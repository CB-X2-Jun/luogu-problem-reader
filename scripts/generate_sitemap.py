#!/usr/bin/env python3
"""
Sitemapç”Ÿæˆå™¨ - è‡ªåŠ¨ç”Ÿæˆç½‘ç«™åœ°å›¾
"""

import datetime
from pathlib import Path
import xml.etree.ElementTree as ET

def generate_sitemap():
    """ç”Ÿæˆsitemap.xml"""
    # åˆ›å»ºæ ¹å…ƒç´ 
    urlset = ET.Element('urlset')
    urlset.set('xmlns', 'http://www.sitemaps.org/schemas/sitemap/0.9')
    
    base_url = 'https://luogu.cb-x2-jun.run.place'
    current_date = datetime.datetime.now().strftime('%Y-%m-%d')
    
    # æ·»åŠ ä¸»é¡µ
    url = ET.SubElement(urlset, 'url')
    ET.SubElement(url, 'loc').text = f'{base_url}/'
    ET.SubElement(url, 'lastmod').text = current_date
    ET.SubElement(url, 'changefreq').text = 'daily'
    ET.SubElement(url, 'priority').text = '1.0'
    
    # æ·»åŠ é¢˜ç›®åˆ—è¡¨é¡µ
    url = ET.SubElement(urlset, 'url')
    ET.SubElement(url, 'loc').text = f'{base_url}/problem/list/'
    ET.SubElement(url, 'lastmod').text = current_date
    ET.SubElement(url, 'changefreq').text = 'daily'
    ET.SubElement(url, 'priority').text = '0.9'
    
    # æ·»åŠ æ‰€æœ‰é¢˜ç›®é¡µé¢
    problem_dir = Path('problem')
    problem_count = 0
    
    for problem_path in sorted(problem_dir.glob('P*/')):
        if not problem_path.is_dir():
            continue
            
        problem_id = problem_path.name
        md_file = problem_path / 'index.md'
        html_file = problem_path / 'index.html'
        
        if not md_file.exists() or not html_file.exists():
            continue
        
        # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        mod_time = datetime.datetime.fromtimestamp(html_file.stat().st_mtime)
        lastmod = mod_time.strftime('%Y-%m-%d')
        
        url = ET.SubElement(urlset, 'url')
        ET.SubElement(url, 'loc').text = f'{base_url}/problem/{problem_id}/'
        ET.SubElement(url, 'lastmod').text = lastmod
        ET.SubElement(url, 'changefreq').text = 'weekly'
        ET.SubElement(url, 'priority').text = '0.8'
        
        problem_count += 1
    
    # æ ¼å¼åŒ–XML
    def indent(elem, level=0):
        i = "\n" + level*"  "
        if len(elem):
            if not elem.text or not elem.text.strip():
                elem.text = i + "  "
            if not elem.tail or not elem.tail.strip():
                elem.tail = i
            for elem in elem:
                indent(elem, level+1)
            if not elem.tail or not elem.tail.strip():
                elem.tail = i
        else:
            if level and (not elem.tail or not elem.tail.strip()):
                elem.tail = i
    
    indent(urlset)
    
    # ä¿å­˜sitemap
    tree = ET.ElementTree(urlset)
    tree.write('sitemap.xml', encoding='utf-8', xml_declaration=True)
    
    print(f"ğŸ—ºï¸ Sitemapå·²ç”Ÿæˆï¼ŒåŒ…å« {problem_count + 2} ä¸ªURL")
    return problem_count + 2

def generate_robots_txt():
    """ç”Ÿæˆrobots.txt"""
    robots_content = """User-agent: *
Allow: /

# Sitemap
Sitemap: https://luogu.cb-x2-jun.run.place/sitemap.xml

# ä¼˜åŒ–çˆ¬è™«è¡Œä¸º
Crawl-delay: 1

# å…è®¸è®¿é—®æ‰€æœ‰é¢˜ç›®
Allow: /problem/
Allow: /problem/list/

# ç»Ÿè®¡æ–‡ä»¶å¯ä»¥è¢«ç´¢å¼•
Allow: /stats/
"""
    
    with open('robots.txt', 'w', encoding='utf-8') as f:
        f.write(robots_content)
    
    print("ğŸ¤– robots.txtå·²ç”Ÿæˆ")

def main():
    print("ğŸš€ å¼€å§‹ç”ŸæˆSEOæ–‡ä»¶...")
    
    url_count = generate_sitemap()
    generate_robots_txt()
    
    print(f"\nâœ… SEOæ–‡ä»¶ç”Ÿæˆå®Œæˆï¼å…± {url_count} ä¸ªURL")

if __name__ == '__main__':
    main()
